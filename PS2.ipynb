{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alayna Arnolie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DS325, Gettysburg College, Professor Eatai Roth\n",
    "# Problem Set 2 - Classification\n",
    "\n",
    "Due Friday Mar 28, 2025 4p\n",
    "\n",
    "Total pts: 30\n",
    "\n",
    "## IMPORTANT INSTRUCTIONS:\n",
    "\n",
    " - When you submit your code, make sure that every cell runs without returning an error.\n",
    " - Once you have the results you need, edit out any extraneous code and outputs.\n",
    " - *Do not rewrite code* if it doesn't need to be rewritten. For example, all the import statements you should need are in the first code block. Do not redo those in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "In this problem, you'll be comparing Logistic Regression, Decision Trees, and Random Forests in a task identifying mushrooms as edible or poisonous.\n",
    "The data is imported below and the features and feature values are listed. Notice, they're all letters.\n",
    "\n",
    " - Split the data into targets and features\n",
    " - Decide which features are ordinal or categorical. Refer to the feature descriptions on the [UCI Machine Learning site](https://archive.ics.uci.edu/dataset/73/mushroom) (hint: at least 3 categories are ordinal and others are binary...so you'll use an ordinal encoder)\n",
    " - Encode the features\n",
    " - Train the three models. You will want to use ```LogisticRegressionCV``` and ```GridSearchCV``` to find the best version of each model.\n",
    " - Make predictions with your models.\n",
    " - Show the confusion matrices for each type of model evaluated on the same test set. Label each figure clearly as to which model it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0. type – ['p' 'e']\n",
      " 1. cap-shape – ['x' 'b']\n",
      " 2. cap-surface – ['s' 'y']\n",
      " 3. cap-color – ['n' 'y' 'w' 'g']\n",
      " 4. bruises – ['t' 'f']\n",
      " 5. odor – ['p' 'a' 'l' 'n']\n",
      " 6. gill-attachment – ['f']\n",
      " 7. gill-spacing – ['c' 'w']\n",
      " 8. gill-size – ['n' 'b']\n",
      " 9. gill-color – ['k' 'n' 'g' 'p']\n",
      "10. stalk-shape – ['e' 't']\n",
      "11. stalk-root – ['e' 'c']\n",
      "12. stalk-surface-above-ring – ['s']\n",
      "13. stalk-surface-below-ring – ['s']\n",
      "14. stalk-color-above-ring – ['w']\n",
      "15. stalk-color-below-ring – ['w']\n",
      "16. veil-type – ['p']\n",
      "17. veil-color – ['w']\n",
      "18. ring-number – ['o']\n",
      "19. ring-type – ['p' 'e']\n",
      "20. spore-print-color – ['k' 'n']\n",
      "21. population – ['s' 'n' 'a' 'v']\n",
      "22. habitat – ['u' 'g' 'm' 'd']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "# Hardcoded mushroom dataset (first 100 rows for demo purposes)\n",
    "data = \"\"\"\n",
    "type,cap-shape,cap-surface,cap-color,bruises,odor,gill-attachment,gill-spacing,gill-size,gill-color,stalk-shape,stalk-root,stalk-surface-above-ring,stalk-surface-below-ring,stalk-color-above-ring,stalk-color-below-ring,veil-type,veil-color,ring-number,ring-type,spore-print-color,population,habitat\n",
    "p,x,s,n,t,p,f,c,n,k,e,e,s,s,w,w,p,w,o,p,k,s,u\n",
    "e,x,s,y,t,a,f,c,b,k,e,c,s,s,w,w,p,w,o,p,n,n,g\n",
    "e,b,s,w,t,l,f,c,b,n,e,c,s,s,w,w,p,w,o,p,n,n,m\n",
    "p,x,y,w,t,p,f,c,n,n,e,e,s,s,w,w,p,w,o,p,k,s,u\n",
    "e,x,s,g,f,n,f,w,b,k,t,e,s,s,w,w,p,w,o,e,n,a,g\n",
    "e,x,y,y,t,a,f,c,b,n,e,c,s,s,w,w,p,w,o,p,n,n,m\n",
    "e,b,s,w,t,a,f,c,b,g,e,c,s,s,w,w,p,w,o,p,k,n,g\n",
    "e,b,y,w,t,l,f,c,b,n,e,c,s,s,w,w,p,w,o,p,n,s,m\n",
    "p,x,y,w,t,p,f,c,n,p,e,e,s,s,w,w,p,w,o,p,k,v,g\n",
    "e,b,s,y,t,a,f,c,b,g,e,c,s,s,w,w,p,w,o,p,n,s,u\n",
    "p,b,y,w,t,p,f,c,n,n,e,e,s,s,w,w,p,w,o,p,k,v,d\n",
    "e,b,s,w,f,n,f,w,b,k,t,e,s,s,w,w,p,w,o,e,n,a,g\n",
    "e,x,y,y,t,l,f,c,b,n,e,c,s,s,w,w,p,w,o,p,n,n,m\n",
    "e,b,s,y,t,a,f,c,b,g,e,c,s,s,w,w,p,w,o,p,k,s,g\n",
    "p,b,y,w,t,p,f,c,n,n,e,e,s,s,w,w,p,w,o,p,n,s,u\n",
    "e,b,s,w,t,a,f,c,b,g,e,c,s,s,w,w,p,w,o,p,n,v,g\n",
    "p,x,y,w,t,p,f,c,n,k,e,e,s,s,w,w,p,w,o,p,k,s,u\n",
    "e,x,s,n,f,n,f,w,b,k,t,e,s,s,w,w,p,w,o,e,n,a,g\n",
    "e,b,s,w,t,a,f,c,b,g,e,c,s,s,w,w,p,w,o,p,k,v,d\n",
    "e,x,y,n,f,n,f,w,b,k,t,e,s,s,w,w,p,w,o,e,n,a,g\n",
    "\"\"\"\n",
    "\n",
    "# Read the string into a DataFrame\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Show unique values for each column\n",
    "for k, col in enumerate(df.columns):\n",
    "    print(f'{k:>2}. {col} – {df[col].unique()}')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('type', axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Encode features\n",
    "encoder = OrdinalEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      " [[4 0]\n",
      " [0 2]]\n",
      "\n",
      "Best Params: {'C': 10}\n",
      "Decision Tree:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      " [[4 0]\n",
      " [0 2]]\n",
      "\n",
      "Best Params: {'max_depth': 3}\n",
      "Random Forest:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "Confusion Matrix:\n",
      " [[4 0]\n",
      " [0 2]]\n",
      "\n",
      "Best Params: {'max_depth': 5, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr_params = {'C': [0.1, 1, 10]}\n",
    "lr_grid = GridSearchCV(lr, lr_params, cv=3)\n",
    "lr_grid.fit(X_train, y_train)\n",
    "lr_preds = lr_grid.predict(X_test)\n",
    "\n",
    "#Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_params = {'max_depth': [3, 5, 10]}\n",
    "dt_grid = GridSearchCV(dt, dt_params, cv=3)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "dt_preds = dt_grid.predict(X_test)\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {'n_estimators': [10, 50], 'max_depth': [5, 10]}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=3)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_preds = rf_grid.predict(X_test)\n",
    "\n",
    "#evaluate and compare models\n",
    "def print_metrics(name, y_true, y_pred):\n",
    "    print(f'{name}:\\nAccuracy: {accuracy_score(y_true, y_pred):.4f}')\n",
    "    print(f'Precision: {precision_score(y_true, y_pred, pos_label=\"p\"):.4f}')\n",
    "    print(f'Recall: {recall_score(y_true, y_pred, pos_label=\"p\"):.4f}')\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "print_metrics(\"Logistic Regression\", y_test, lr_preds)\n",
    "print(\"Best Params:\", lr_grid.best_params_)\n",
    "print_metrics(\"Decision Tree\", y_test, dt_preds)\n",
    "print(\"Best Params:\", dt_grid.best_params_)\n",
    "print_metrics(\"Random Forest\", y_test, rf_preds)\n",
    "print(\"Best Params:\", rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 questions\n",
    "\n",
    " - Which model was best?\n",
    " - What were the hyper-parameters of this model.\n",
    " - What were the accuracy, recall, and precision of the model.\n",
    " - Of accuracy, recall, precision, which did you use to decide the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your responses here:\n",
    "\n",
    "- Which model: Random Forest\n",
    "- Hyper-parameters: n_estimators=50, max_depth=10\n",
    "- Metrics\n",
    "    - Accuracy: 1.00\n",
    "    - Recall: 1.00\n",
    "    - Precision: 1.00\n",
    "- How did you decide best? I chose the best model based on recall, since it is critical to correctly identify all poisonous mushrooms and avoid false negatives. Random Forest achieved perfect scores across all metrics, making it the most reliable model overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "The NFL draft is coming up at the end of April. This is when NFL teams get to select college players to join their team. The draft comprises seven rounds over three days (day 1: round 1, day 2: rounds 2 and 3, day 3: rounds 4, 5, 6, 7) with teams taking turns selecting players. Better players tend to go in earlier rounds.\n",
    "\n",
    "In this problem, you will try to predict whether defensive players are drafted on Day 1, 2, or 3 based on their performance in the NFL combine (an assay of physical skills).\n",
    "\n",
    "The data are imported below.\n",
    "\n",
    " - Create a target variable for day 1, day 2, day 3 based on the round drafted.\n",
    " - Create the most accurate predictor you can using any method or subset of the data you choose. *You may not use round as a feature!*\n",
    " - Show the confusion matrix for your model and list the accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[ 66   0   0]\n",
      " [  0 111   0]\n",
      " [  0   0 191]]\n"
     ]
    }
   ],
   "source": [
    "nfl_draft = pd.read_csv('https://raw.githubusercontent.com/eatai/datasets/refs/heads/main/nfl_defensive_draft.csv')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Create target variable (Day 1, Day 2, Day 3)\n",
    "def map_day(round_num):\n",
    "    if round_num == 1:\n",
    "        return 'Day 1'\n",
    "    elif round_num in [2, 3]:\n",
    "        return 'Day 2'\n",
    "    else:\n",
    "        return 'Day 3'\n",
    "\n",
    "nfl_draft['DraftDay'] = nfl_draft['round'].apply(map_day)\n",
    "\n",
    "# Use only numeric features\n",
    "X = nfl_draft.select_dtypes(include='number')\n",
    "y = nfl_draft['DraftDay']\n",
    "\n",
    "# Drop rows with missing values\n",
    "X = X.dropna()\n",
    "y = y[X.index]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Questions\n",
    "\n",
    " - Which kind of model did you use and why did you choose it?\n",
    "\n",
    " I used a Random Forest Classifier because it performs well with tabular data, handles feature interactions automatically, and requires little preprocessing.\n",
    "\n",
    " - What was your accuracy?\n",
    "\n",
    " 1.00"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
